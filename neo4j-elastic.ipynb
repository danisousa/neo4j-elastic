{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils\n",
    "import json\n",
    "import os\n",
    "from os import path\n",
    "import subprocess\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Dependency Tree\n",
    "from xml.etree import ElementTree\n",
    "from xml.dom import minidom\n",
    "import xml.etree.ElementTree as ET\n",
    "from xml.etree.ElementTree import Element, SubElement, Comment, tostring, ElementTree\n",
    "\n",
    "# BBDD\n",
    "from elasticsearch import Elasticsearch\n",
    "from py2neo import Graph, Node, Relationship\n",
    "from py2neo.matching import *\n",
    "\n",
    "ramas = [\"develop\", \"master\"]"
   ]
  },
  {
   "source": [
    "# Read XML - MAVEN"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find if the edge is between repository or component\n",
    "def findType(tree, elements):\n",
    "    \n",
    "    types = {\"sourceType\":\"\", \"targetType\":\"\"}\n",
    "    types = json.loads(json.dumps(types))\n",
    "    \n",
    "    for elem in tree.iter():\n",
    "        if(elem.attrib.get('id') == elements['source']):\n",
    "            for subelem in elem.iter():\n",
    "                if(subelem.tag.split('}')[1] == 'NodeLabel'):\n",
    "                    info = subelem.text.split(':')\n",
    "                    if(len(info) == 4):\n",
    "                        types['sourceType'] = \"REPOSITORY\"\n",
    "                    else:\n",
    "                        types['sourceType'] = \"LIBRARY\"\n",
    "                        \n",
    "        if(elem.attrib.get('id') == elements['target']):\n",
    "            for subelem in elem.iter():\n",
    "                if(subelem.tag.split('}')[1] == 'NodeLabel'):\n",
    "                    info = subelem.text.split(':')\n",
    "                    if(len(info) == 4):\n",
    "                        types['targetType'] = \"REPOSITORY\"\n",
    "                    else:\n",
    "                        types['targetType'] = \"LIBRARY\"\n",
    "\n",
    "    return types\n",
    "\n",
    "\n",
    "def find_ids(tree, elements):\n",
    "    types = {\"sourceID\":\"\", \"targetID\":\"\"}\n",
    "    types = json.loads(json.dumps(types))\n",
    "    \n",
    "    for elem in tree.iter():\n",
    "        if(elem.attrib.get('id') == elements['source']):\n",
    "            for subelem in elem.iter():\n",
    "                if(subelem.tag.split('}')[1] == 'NodeLabel'):\n",
    "                    info = subelem.text.split(':')\n",
    "                    if(len(info) == 4):\n",
    "                        types['sourceID'] = info[1]\n",
    "                    else:\n",
    "                        new_id = info[1]+'@'+info[3]\n",
    "                        types['sourceID'] = new_id\n",
    "                        \n",
    "        if(elem.attrib.get('id') == elements['target']):\n",
    "            for subelem in elem.iter():\n",
    "                if(subelem.tag.split('}')[1] == 'NodeLabel'):\n",
    "                    info = subelem.text.split(':')\n",
    "                    if(len(info) == 4):\n",
    "                        types['targetID'] = info[1]\n",
    "                    else:\n",
    "                        new_id = info[1]+'@'+info[3]\n",
    "                        types['targetID'] = new_id\n",
    "\n",
    "    return types\n",
    "\n",
    "# Parse XML\n",
    "def parse_xml(path_to_file, branch):\n",
    "    # Parse the dependency tree\n",
    "    tree = ET.parse(path_to_file)\n",
    "\n",
    "    # For each element in the XML\n",
    "    for elem in tree.iter():\n",
    "        \n",
    "        # If element is a Node\n",
    "        if(elem.tag.split('}')[1] == 'node'):\n",
    "            id = elem.attrib.get('id')\n",
    "            #print('{}  {}'.format(elem.tag.split('}')[1], elem.attrib))\n",
    "            for subelem in elem.iter():\n",
    "                if(subelem.tag.split('}')[1] == 'NodeLabel'):\n",
    "                    info = subelem.text.split(':')\n",
    "                    \n",
    "                    # If it is the repo info\n",
    "                    if(len(info) == 4):\n",
    "                        # Create repo document\n",
    "                        docu = {\"id\":info[1], \"origin\":info[0], \"packing_type\":info[2], \"technology\":\"java\"}\n",
    "                        docu = json.loads(json.dumps(docu))\n",
    "                        create_node(docu, \"REPOSITORY\")\n",
    "                    elif(len(info) == 5):\n",
    "                        # Create dependency Document\n",
    "                        dep_id = info[1]+'@'+info[3]\n",
    "                        docu = {\"id\":dep_id, \"origin\":info[0], \"name\":info[1], \"packing_type\":info[2], \n",
    "                                \"version\":info[3], \"validated\":\"true\", \"technology\":\"java\"}\n",
    "                        docu = json.loads(json.dumps(docu))\n",
    "                        create_node(docu, \"LIBRARY\")       \n",
    "\n",
    "    for elem in tree.iter():\n",
    "        if(elem.tag.split('}')[1] == 'edge'):\n",
    "            atributos = json.loads(json.dumps(elem.attrib))\n",
    "            types = findType(tree, atributos)\n",
    "            elems_ids = find_ids(tree, atributos)\n",
    "            create_edge(elems_ids, types, branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_GML(path_to_file, branch):\n",
    "\n",
    "    # Parse the dependency tree\n",
    "    parse_xml(path_to_file, branch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read JSON - NODEJS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create document of repository in database\n",
    "def create_node_repo_document(repo):\n",
    "    exists = NodeMatcher(connection).match('LIBRARY', id=repo['name']).first()\n",
    "    # Check if exists\n",
    "    if (exists is None):\n",
    "\n",
    "        # Create Node in Neo4J\n",
    "        new_node = Node('REPOSITORY', id=repo['name'], technology= 'javascript')\n",
    "        connection.create(new_node)\n",
    "        \n",
    "# Create document of dependency in database\n",
    "def create_node_depend_document(dep_data, dep_name):\n",
    "    \n",
    "    #dep_id = dep_name+'@'+dep_data['version']\n",
    "    dep_id = dep_data['from']\n",
    "    exists = NodeMatcher(connection).match('LIBRARY', id=dep_id).first()\n",
    "    \n",
    "    # Check if exists\n",
    "    if (exists is None):\n",
    "        \n",
    "        # Create Node in Neo4J\n",
    "        new_node = Node('LIBRARY', name=dep_name, \n",
    "                               origin=dep_data['from'], \n",
    "                               version=dep_data['version'], \n",
    "                               id=dep_id, \n",
    "                               validated= 'true', \n",
    "                               technology= 'javascript')\n",
    "        \n",
    "        connection.create(new_node)\n",
    "    \n",
    "# Create document of relationship in database\n",
    "def create_node_edge_document(parent, origin, parent_type, branch):\n",
    "    \n",
    "    source = NodeMatcher(connection).match(parent_type, id=parent).first()\n",
    "    destiny = NodeMatcher(connection).match(\"LIBRARY\", id=origin['from']).first()\n",
    "    \n",
    "    # Check if exists\n",
    "    if (source is not None and destiny is not None):\n",
    "        depends = Relationship(source, branch , destiny)\n",
    "        connection.create(depends)\n",
    "        \n",
    "# Check if key has '/'\n",
    "def check_key_format(key):\n",
    "    clave = key\n",
    "    if(\"/\" in key):\n",
    "        clave = clave.replace(\"/\", \":\")\n",
    "    return clave\n",
    "    \n",
    "def get_depend_depth(source, parent, from_type, branch):\n",
    "        \n",
    "    # Check if it has dependencies at this level\n",
    "    if ('dependencies' in source):\n",
    "        deps = source['dependencies']\n",
    "\n",
    "        # For each dependency\n",
    "        for dep in deps:\n",
    "            create_node_depend_document(deps[dep], dep)\n",
    "            create_node_edge_document(parent, deps[dep], from_type, branch)\n",
    "            get_depend_depth(deps[dep], deps[dep]['from'], 'LIBRARY', branch)\n",
    "            \n",
    "# Read JSON with npm dependencies\n",
    "def read_JSON(json_path, branch):\n",
    "\n",
    "    with open(json_path) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "        create_node_repo_document(data)\n",
    "        get_depend_depth(data, data['name'], 'REPOSITORY', branch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neo4J Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('develop', 'rlp@3.3.0', 'rlp@3.3.0')"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "connection = Graph(\"bolt://localhost:7687\", password=\"admin\")\n",
    "\n",
    "# Delete all DB\n",
    "def clean_db():\n",
    "    delete_query = \"MATCH p=()-->() DELETE p\"\n",
    "    connection.run(delete_query)\n",
    "    delete_query = \"MATCH (p) DELETE p\"\n",
    "    connection.run(delete_query)\n",
    "    print(\"Deleted DB data\")\n",
    "    \n",
    "# Create node\n",
    "def create_node(data, tipo):\n",
    "    exists = NodeMatcher(connection).match(tipo, id=data['id']).first()\n",
    "    \n",
    "    # Check if exists\n",
    "    if (exists is None):\n",
    "        \n",
    "        # Create Node in Neo4J\n",
    "        new_node = Node(tipo, **data)\n",
    "        connection.create(new_node)\n",
    "                \n",
    "# Create relationship\n",
    "def create_edge(vertices, tipos, branch):\n",
    "    source = NodeMatcher(connection).match(tipos['sourceType'], id=vertices['sourceID']).first()\n",
    "    destiny = NodeMatcher(connection).match(tipos['targetType'], id=vertices['targetID']).first()\n",
    "    \n",
    "    # Check if exists\n",
    "    if (source is not None and destiny is not None):\n",
    "        depends = Relationship(source, branch , destiny)\n",
    "        connection.create(depends)\n",
    "        \n",
    "    #else:\n",
    "    #    print(\"{} - {}\".format(vertices['sourceID'], vertices['targetID']))\n",
    "        \n",
    "# Update node \n",
    "def update_node(dep_name, dep_version, dep_field, dep_value):\n",
    "    query = 'MATCH (p:LIBRARY) WHERE p.id=\"{name}@{version}\" SET p.{field} = \"{new_value}\" RETURN p'.format(name=dep_name,\n",
    "    version=dep_version,\n",
    "    field=dep_field,\n",
    "    new_value=dep_value)\n",
    "    \n",
    "    result = connection.run(query)\n",
    "    \n",
    "    print(result.data()[0]['p'])\n",
    "    \n",
    "# Search node\n",
    "def search_node(dep_name, dep_version):\n",
    "    query = 'MATCH (p:LIBRARY) WHERE p.id = \"{name}@{version}\" RETURN p.id'.format(name=dep_name,\n",
    "                                                                            version=dep_version)\n",
    "    \n",
    "    cursor = connection.run(query).data()\n",
    "    return cursor[0]['p.id']\n",
    "\n",
    "# Get shortest path between node and not validated one\n",
    "def get_path(dep_name, branch):\n",
    "    query_check = 'MATCH (a), (b) WHERE (a)-[*]-(b) AND a.validated=\"false\" AND b.id=\"{}\" RETURN a.id, b.id'.format(dep_name)\n",
    "    result = connection.run(query_check).data()\n",
    "\n",
    "    if(len(result)>=1):\n",
    "        \n",
    "        unvalid_dep = result[0]['a.id']\n",
    "        query_search = 'MATCH (from:REPOSITORY {{ id:\"{}\" }}) , (to:LIBRARY {{ id: \"{}\" }}) , path = (from)-[:{}*]->(to) RETURN path AS shortestPath, Nodes(path) LIMIT 1'.format(dep_name, unvalid_dep, branch)\n",
    "        path = connection.run(query_search).data()\n",
    "        \n",
    "        if(len(path)>=1):\n",
    "            result_path = path[0]\n",
    "            print(\"{} - {} - KO\".format(dep_name, branch))\n",
    "            print('###############################################')\n",
    "            tab = '\\t'\n",
    "            print(dep_name)\n",
    "            for idx, nodo in enumerate(result_path['Nodes(path)']):\n",
    "                if idx != 0:\n",
    "                    print(tab*idx + '|')\n",
    "                    print(tab*idx + nodo['id'])\n",
    "                    \n",
    "            return 'KO'\n",
    "            \n",
    "    else:\n",
    "        print(\"{} - {} - OK\".format(dep_name, branch))\n",
    "        return 'OK'\n",
    "\n",
    "# Check if one node is affected by not validated deps\n",
    "def check_node(dep_type, dep_name):\n",
    "    \n",
    "    for rama in ramas:\n",
    "        \n",
    "        query_check = 'MATCH (a), (b) WHERE (a)-[*]-(b) AND a.validated=\"false\" AND b.id=\"{}\" RETURN a.id, b.id'.format(dep_name)\n",
    "        result = connection.run(query_check).data()[0]\n",
    "\n",
    "        if(len(result)>=1):\n",
    "\n",
    "            unvalid_dep = result['a.id']\n",
    "            query_search = 'MATCH (from:{} {{ id:\"{}\" }}) , (to:LIBRARY {{ id: \"{}\" }}) , path = (from)-[:{}*]->(to) RETURN path AS shortestPath, Nodes(path) LIMIT 1'.format(dep_type, dep_name, unvalid_dep, rama)\n",
    "\n",
    "            if len(connection.run(query_search).data()) > 0:\n",
    "                path = connection.run(query_search).data()[0]\n",
    "\n",
    "                '''\n",
    "                print(path['Nodes(path)'][0]['id'])\n",
    "                print(path['Nodes(path)'][1]['id'])\n",
    "                print(path['Nodes(path)'][len(path['Nodes(path)'])-1]['id'])\n",
    "                '''\n",
    "\n",
    "                return rama, path['Nodes(path)'][1]['id'], path['Nodes(path)'][len(path['Nodes(path)'])-1]['id']\n",
    "\n",
    "            else:\n",
    "                print(\"NODE {} in branch {} - OK\".format(dep_name, branch))\n",
    "    \n",
    "    return 0\n",
    "\n",
    "#update_node(\"hamcrest-core\", \"1.3\", \"validated\", \"false\")\n",
    "#search_node(\"hamcrest-core\", \"1.3\")\n",
    "check_node(\"LIBRARY\", \"crypto@3.6.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elastic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top branch in wich the dependency is used\n",
    "def get_top_branch(dep_id):\n",
    "    query_check = \"MATCH (:LIBRARY {{id: '{}' }})-[r]-() RETURN TYPE(r)\".format(dep_id)\n",
    "    result = connection.run(query_check).data()\n",
    "    \n",
    "    for resultado in result:\n",
    "        branch_name = resultado['TYPE(r)']\n",
    "        \n",
    "        if branch_name == \"master\":\n",
    "            return \"master\"\n",
    "        else:\n",
    "            return \"develop\"\n",
    "        \n",
    "def write_catalog():\n",
    "    DATE = datetime.now()\n",
    "    \n",
    "    query_check = 'MATCH (n) RETURN n'\n",
    "    result = connection.run(query_check).data()\n",
    "    \n",
    "    for nodo in result:\n",
    "        write_elastic(str(nodo['n'].labels), nodo['n'], DATE)\n",
    "\n",
    "def write_elastic(dep_type, data, fecha_actual):\n",
    "    doc = {}\n",
    "    index_sufix = \"\"\n",
    "    \n",
    "    if dep_type == ':LIBRARY':\n",
    "        \n",
    "        if data['id'].startswith('@'):\n",
    "            nombre, version = data['id'].split('@')[1:]\n",
    "        else:\n",
    "            nombre, version = data['id'].split('@')\n",
    "            \n",
    "        index_sufix = \"library\"\n",
    "        \n",
    "        doc = {\n",
    "            'timestamp': fecha_actual,\n",
    "            'library.id': data['id'],\n",
    "            'library.name': nombre,\n",
    "            'library.type': index_sufix,\n",
    "            'library.version': version,\n",
    "            'library.validated': data['validated'],\n",
    "            'library.top-branch': get_top_branch(data['id']),\n",
    "            'library.technology': data['technology']\n",
    "        }\n",
    "        \n",
    "    elif dep_type == ':REPOSITORY':\n",
    "        index_sufix = \"repository\"\n",
    "        \n",
    "        rama = check_node(\"REPOSITORY\", data['id'])\n",
    "                    \n",
    "        doc = {\n",
    "            'timestamp': fecha_actual,\n",
    "            'type': index_sufix,\n",
    "            'repository.name': data['id'],\n",
    "            'repository.technology': data['technology']\n",
    "        }            \n",
    "        \n",
    "    elif dep_type == ':APPLICATION':\n",
    "        index_sufix = \"application\"\n",
    "        doc = {\n",
    "            'timestamp': fecha_actual,\n",
    "            'type': index_sufix,\n",
    "            'application.name': data['id'],\n",
    "            'application.technology': data['technology']\n",
    "        }\n",
    "        \n",
    "    res = es.index(index=\"test-inventory-{}\".format(index_sufix), doc_type='_doc', body=doc)\n",
    "    #print(res['result'])\n",
    "    #es.indices.refresh(index=\"test-index\")\n",
    "    \n",
    "# Clear Elastic Index\n",
    "def clean_elastic():\n",
    "    \n",
    "    idx_list = [x for x in es.indices.get_alias(\"test-*\").keys() ]\n",
    "\n",
    "    for index in idx_list:\n",
    "        es.indices.delete(index=index, ignore=[400, 404])\n",
    "    \n",
    "    print('Deleted Elasticsearch Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_pipeline(pipe_status, branch):\n",
    "    DATE = datetime.now()\n",
    "\n",
    "    doc = {}\n",
    "    \n",
    "    if pipe_status == 'OK':\n",
    "                    \n",
    "        doc = {\n",
    "            'timestamp': DATE,\n",
    "            'pipeline.id': 'sample-project-maven',\n",
    "            'pipeline.status': 'OK',\n",
    "            'pipeline.technology': 'java'\n",
    "        }\n",
    "        \n",
    "        \n",
    "    elif pipe_status == 'KO':\n",
    "\n",
    "        results = check_node(\"sample-project-maven\", branch)\n",
    "\n",
    "        doc = {\n",
    "            'timestamp': DATE,\n",
    "            'pipeline.id': 'sample-project-maven',\n",
    "            'pipeline.status': 'KO',\n",
    "            'pipeline.origin': results[1],\n",
    "            'pipeline.library_compromised': results[0],\n",
    "            'pipeline.technology': 'java'\n",
    "        }\n",
    "                \n",
    "    res = es.index(index=\"test-pipeline-{}\".format(pipe_status.lower()), doc_type='_doc', body=doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un contenedor para ampliar la jerarquia\n",
    "def create_container():\n",
    "    \n",
    "    application_name = \"my-application\"\n",
    "    # Create document of dependency in database    \n",
    "    exists = NodeMatcher(connection).match('APPLICATION', id=application_name).first()\n",
    "    \n",
    "    # Check if exists\n",
    "    if (exists is None):\n",
    "        \n",
    "        # Create Node in Neo4J\n",
    "        new_node = Node('APPLICATION', id=application_name)\n",
    "        aux_repo = Node('REPOSITORY', id=\"auxiliar-repo\")\n",
    "        \n",
    "        connection.create(new_node)\n",
    "        connection.create(aux_repo)\n",
    "        \n",
    "        source = NodeMatcher(connection).match(\"APPLICATION\", id=application_name).first()\n",
    "        destiny = NodeMatcher(connection).match(\"REPOSITORY\", id=\"sample-project-maven\").first()\n",
    "    \n",
    "        # Check if exists\n",
    "        if (source is not None and destiny is not None):\n",
    "            depends = Relationship(source, \"contiene\" , destiny)\n",
    "            connection.create(depends)\n",
    "            \n",
    "        source = NodeMatcher(connection).match(\"APPLICATION\", id=application_name).first()\n",
    "        destiny = NodeMatcher(connection).match(\"REPOSITORY\", id=\"auxiliar-repo\").first()\n",
    "    \n",
    "        # Check if exists\n",
    "        if (source is not None and destiny is not None):\n",
    "            depends = Relationship(source, \"contiene\" , destiny)\n",
    "            connection.create(depends)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0: Reset BBDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Deleted DB data\n",
      "Deleted Elasticsearch Data\n",
      "C:\\Users\\d.garcia.sousa\\Anaconda3\\envs\\my-env\\lib\\site-packages\\elasticsearch\\connection\\base.py:208: ElasticsearchWarning: this request accesses aliases with names reserved for system indices: [.kibana_task_manager_7.13.0, .kibana, .kibana_task_manager, .kibana_7.13.0, .security], but in a future major version, directaccess to system indices and their aliases will not be allowed\n",
      "  warnings.warn(message, category=ElasticsearchWarning)\n"
     ]
    }
   ],
   "source": [
    "clean_db()\n",
    "es = Elasticsearch(hosts=\"http://elastic:changeme@localhost:9200/\")\n",
    "\n",
    "clean_elastic()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Linea Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "list index out of range",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-54f475bc9d2a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mread_GML\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaven_path\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrama\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrama\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mcreate_container\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mwrite_catalog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[1;31m#read_JSON(npm_path.format(rama), rama)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-e8886fac8366>\u001b[0m in \u001b[0;36mwrite_catalog\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mnodo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mwrite_elastic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnodo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'n'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnodo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'n'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDATE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mwrite_elastic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdep_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfecha_actual\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-e8886fac8366>\u001b[0m in \u001b[0;36mwrite_elastic\u001b[1;34m(dep_type, data, fecha_actual)\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[0mindex_sufix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"repository\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m         \u001b[0mrama\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"REPOSITORY\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m         doc = {\n",
      "\u001b[1;32m<ipython-input-19-74a725314236>\u001b[0m in \u001b[0;36mcheck_node\u001b[1;34m(dep_type, dep_name)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[0mquery_check\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'MATCH (a), (b) WHERE (a)-[*]-(b) AND a.validated=\"false\" AND b.id=\"{}\" RETURN a.id, b.id'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdep_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery_check\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "maven_path = 'C:\\\\Users\\\\d.garcia.sousa\\\\Documents\\\\Vodafone\\\\repositories\\\\sample-project-maven\\\\out-{}.gml'\n",
    "npm_path = 'C:\\\\Users\\\\d.garcia.sousa\\\\Documents\\\\Vodafone\\\\repositories\\\\sample-project-npm\\\\outfile-{}.json'\n",
    "\n",
    "\n",
    "for rama in ramas:\n",
    "    read_GML(maven_path.format(rama), rama)\n",
    "    create_container()\n",
    "    write_catalog()\n",
    "    #read_JSON(npm_path.format(rama), rama)\n",
    "    \n",
    "    # Check deps\n",
    "    status = get_path(\"sample-project-maven\", rama)\n",
    "    write_pipeline(status, rama)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Marcar Dependencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(_10:LIBRARY {id: 'rlp@3.3.0', name: 'rlp', origin: 'org.web3j', packing_type: 'jar', technology: 'java', validated: 'false', version: '3.3.0'})\n"
     ]
    }
   ],
   "source": [
    "update_node(\"rlp\", \"3.3.0\", \"validated\", \"false\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Comprobar Repositorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "develop\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "list index out of range",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-184b75c390f8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mread_GML\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaven_path\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrama\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrama\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mcreate_container\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mwrite_catalog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[1;31m#read_JSON(npm_path.format(rama), rama)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-e8886fac8366>\u001b[0m in \u001b[0;36mwrite_catalog\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mnodo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mwrite_elastic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnodo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'n'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnodo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'n'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDATE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mwrite_elastic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdep_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfecha_actual\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-e8886fac8366>\u001b[0m in \u001b[0;36mwrite_elastic\u001b[1;34m(dep_type, data, fecha_actual)\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[0mindex_sufix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"repository\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m         \u001b[0mrama\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"REPOSITORY\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m         doc = {\n",
      "\u001b[1;32m<ipython-input-19-74a725314236>\u001b[0m in \u001b[0;36mcheck_node\u001b[1;34m(dep_type, dep_name)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[0mquery_check\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'MATCH (a), (b) WHERE (a)-[*]-(b) AND a.validated=\"false\" AND b.id=\"{}\" RETURN a.id, b.id'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdep_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery_check\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "maven_path = 'C:\\\\Users\\\\d.garcia.sousa\\\\Documents\\\\Vodafone\\\\repositories\\\\sample-project-maven\\\\out-{}.gml'\n",
    "npm_path = 'C:\\\\Users\\\\d.garcia.sousa\\\\Documents\\\\Vodafone\\\\repositories\\\\sample-project-npm\\\\outfile-{}.json'\n",
    "\n",
    "for rama in ramas:\n",
    "    print(rama)\n",
    "    read_GML(maven_path.format(rama), rama)\n",
    "    create_container()\n",
    "    write_catalog()\n",
    "    #read_JSON(npm_path.format(rama), rama)\n",
    "    \n",
    "    # Check deps\n",
    "    status = get_path(\"sample-project-maven\", rama)\n",
    "    \n",
    "    if(rama == \"master\"):\n",
    "        status='OK'\n",
    "\n",
    "    write_pipeline(status, rama)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('my-env': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false,
  "interpreter": {
   "hash": "3d5c3a65d9d047e7b29420a333fee86f9b357f02875a4f569d2e467a027def39"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}